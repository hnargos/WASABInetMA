{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "import pkg_resources\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from torch import as_tensor as pytT\n",
    "from torch import float32 as pytFl32\n",
    "from torch import save\n",
    "\n",
    "import bmctool\n",
    "from bmctool.bmc_tool import BMCTool\n",
    "from bmctool.set_params import load_params\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check BMCTool version (used version = 0.4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_resources.get_distribution('bmctool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all files/configs/parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select config and seq file\n",
    "config_name = 'config_WASABITI_sequential'\n",
    "seq_name = '20210706_WASABITI_sweep12_sim'\n",
    "\n",
    "# select size\n",
    "dist_sizes = {'tiny': 2 ** 12, 'small': 2 ** 15, 'medium': 2 ** 18, 'large': 2 ** 21}\n",
    "my_size = 'small'  # can be 'tiny', 'small', 'medium' or 'large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load settings from configs and define size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join('../../../library', config_name + '.yaml')\n",
    "seq_file = os.path.join('../../../library', seq_name + '.seq')\n",
    "\n",
    "sim_params = load_params(config_file)\n",
    "sim_params.print_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define output folder and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_addition = ''\n",
    "\n",
    "filepath_output = pathlib.Path.home().parent.parent / 'data' / 'schuen02' / 'train_data'\n",
    "if not os.path.exists(filepath_output):\n",
    "    os.makedirs(filepath_output)\n",
    "    print('created a new folder for the data')\n",
    "    \n",
    "sizefolder_name = 'example_' + my_size\n",
    "sizefolder_path = os.path.join(filepath_output, sizefolder_name)\n",
    "if not os.path.exists(sizefolder_path):\n",
    "    os.makedirs(sizefolder_path)\n",
    "    print(f'created a new subfolder \"{sizefolder_path}\" in {filepath_output} folder')\n",
    "    \n",
    "subfolder_name = f'{time.strftime(\"%Y%m%d\")}_{seq_name}{name_addition}'\n",
    "subfolder_path = os.path.join(sizefolder_path, subfolder_name)\n",
    "if not os.path.exists(subfolder_path):\n",
    "    os.makedirs(subfolder_path)\n",
    "    print(f'created a new subfolder \"{subfolder_path}\" in {sizefolder_path} folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create T1 and T2 distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# B0 distribution\n",
    "##################################################################\n",
    "\n",
    "b0_lim = [-1.0, 1.0]\n",
    "b0_mean = 0\n",
    "b0_scale = 0.6\n",
    "\n",
    "b0_dist = stats.truncnorm((b0_lim[0] - b0_mean) / b0_scale, \n",
    "                          (b0_lim[1] - b0_mean) / b0_scale,\n",
    "                          loc=b0_mean, \n",
    "                          scale=b0_scale)\n",
    "\n",
    "##################################################################\n",
    "# B1 distribution\n",
    "##################################################################\n",
    "\n",
    "b1_lim = [0.2, 2.0]\n",
    "b1_mean = 1\n",
    "b1_scale = 0.7\n",
    "\n",
    "b1_dist = stats.truncnorm((b1_lim[0] - b1_mean) / b1_scale, \n",
    "                          (b1_lim[1] - b1_mean) / b1_scale,\n",
    "                          loc=b1_mean, \n",
    "                          scale=b1_scale)\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# T1 distribution\n",
    "##################################################################\n",
    "t1_lim = [0.05, 7]\n",
    "t1_mean = [1.5, 0]\n",
    "t1_scale = [0.75, 3.5]        \n",
    "    \n",
    "t1_dist1 = stats.truncnorm(a=(t1_lim[0] - t1_mean[0]) / t1_scale[0],\n",
    "                           b=(t1_lim[1] - t1_mean[0]) / t1_scale[0],\n",
    "                           loc=t1_mean[0], \n",
    "                           scale=t1_scale[0])\n",
    "\n",
    "t1_dist2 = stats.truncnorm(a=(t1_lim[0] - t1_mean[1]) / t1_scale[1],\n",
    "                           b=(t1_lim[1] - t1_mean[1]) / t1_scale[1],\n",
    "                           loc=t1_mean[1], \n",
    "                           scale=t1_scale[1])\n",
    "\n",
    "t1_vals = np.append(t1_dist1.rvs(size=int(10e6)),t1_dist2.rvs(size=int(10e6)))\n",
    "\n",
    "##################################################################\n",
    "# T2 distribution\n",
    "##################################################################\n",
    "t2_lim = [0.005, 5]\n",
    "t2_mean = [0.20, 0]\n",
    "t2_scale = [0.1, 2.5]        \n",
    "    \n",
    "t2_dist1 = stats.truncnorm(a=(t2_lim[0] - t2_mean[0]) / t2_scale[0],\n",
    "                           b=(t2_lim[1] - t2_mean[0]) / t2_scale[0],\n",
    "                           loc=t2_mean[0], \n",
    "                           scale=t2_scale[0])\n",
    "\n",
    "t2_dist2 = stats.truncnorm(a=(t2_lim[0] - t2_mean[1]) / t2_scale[1],\n",
    "                           b=(t2_lim[1] - t2_mean[1]) / t2_scale[1],\n",
    "                           loc=t2_mean[1], \n",
    "                           scale=t2_scale[1])\n",
    "\n",
    "\n",
    "\n",
    "t2_vals = np.append(t2_dist1.rvs(size=int(5e6)),t2_dist2.rvs(size=int(15e6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = []\n",
    "specs = []\n",
    "\n",
    "Sim = BMCTool(sim_params, seq_file, verbose=False)\n",
    "print(f'Simulating {dist_sizes[my_size]} z-spectra.\\n')\n",
    "\n",
    "n_t1 = t1_vals.size\n",
    "n_t2 = t2_vals.size\n",
    "\n",
    "loopstart = time.time()\n",
    "print(f'Running simulations for {seq_name} now.')\n",
    "for n in range(dist_sizes[my_size]):\n",
    "    b0_ = b0_dist.rvs(size=1)[0]\n",
    "    b1_ = b1_dist.rvs(size=1)[0]\n",
    "    t1_ = t1_vals[np.random.randint(n_t1)]\n",
    "    t2_ = t2_vals[np.random.randint(n_t2)]\n",
    "    sim_params.update_scanner(b0_inhom=b0_, rel_b1=b1_)\n",
    "    sim_params.update_water_pool(r1=1/t1_, r2=1/t2_)\n",
    "\n",
    "    # update parameters and run simulation\n",
    "    Sim.params = sim_params\n",
    "    Sim.run()\n",
    "\n",
    "    # write spectrum and parameters\n",
    "    specs.append(Sim.get_zspec(return_abs=False)[1])\n",
    "    pars.append([b0_, b1_, t1_, t2_])\n",
    "\n",
    "    # update progress bar and estimated time\n",
    "    if n%100 == 0:\n",
    "        b = int(60 * (n+1) / dist_sizes[my_size])\n",
    "        left = int(60 - b)\n",
    "        loopremain = (time.time() - loopstart) * (dist_sizes[my_size] - (n+1)) / ((n+1) * 60)\n",
    "        print('[' + '#' * b + '-' * left + ']' + \n",
    "              f' Estimated remaining time {loopremain:.1f} minutes.', end='\\r')\n",
    "\n",
    "# convert lists to arrays\n",
    "specs = np.array(specs)\n",
    "pars = np.array(pars)\n",
    "\n",
    "print(' \\n ')\n",
    "print(f'Simulation took {(time.time() - loopstart) / 60:.3f} minutes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histrograms of param values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,8))\n",
    "try:\n",
    "    ax[0,0].hist(pars[:,0], bins=100)\n",
    "    ax[0,0].set_title('B0')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    ax[0,1].hist(pars[:,1], bins=100)\n",
    "    ax[0,1].set_title('B1')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    ax[1,0].hist(pars[:,2], bins=100)\n",
    "    ax[1,0].set_title('T1')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    ax[1,1].hist(pars[:,3], bins=100)\n",
    "    ax[1,1].set_title('T2')\n",
    "except:\n",
    "    pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some random spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spec = 10\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(n_spec):\n",
    "    ax.plot(specs[i+10, 1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_addition = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data and convert to pytorch tensor\n",
    "X = pytT(specs, dtype=pytFl32)\n",
    "y = pytT(pars, dtype=pytFl32)\n",
    "\n",
    "# save data with pytorch\n",
    "filepath_save_X = os.path.join(subfolder_path, f'{time.strftime(\"%Y%m%d\")}_X_{seq_name}{name_addition}.pt')\n",
    "filepath_save_y = os.path.join(subfolder_path, f'{time.strftime(\"%Y%m%d\")}_y_{seq_name}{name_addition}.pt')\n",
    "\n",
    "save (X, filepath_save_X)\n",
    "save (y, filepath_save_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save copy of notebook in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "\n",
    "current_notebook_name = 'create_data_sweep12_small.ipynb'\n",
    "current_notebook_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "try:\n",
    "    copy2(os.path.join(current_notebook_path, current_notebook_name),\n",
    "          os.path.join(subfolder_path, f'{time.strftime(\"%Y%m%d\")}_{seq_name}{name_addition}_create_data.ipynb'))\n",
    "    print(f'Saved a copy of the current notebook in {subfolder_path}.')\n",
    "except:\n",
    "    print(f'Copying {os.path.join(current_notebook_path, current_notebook_name)} to {subfolder_path} failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
